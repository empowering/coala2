{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 엑셀 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>likes</th>\n",
       "      <th>isAd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>결혼 전 신혼 살림 빠짐없이 차리면서\\n\\n이만~하면 되었다~~했고요\\n\\n그 이후...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; 장점 &gt;\\n\\n \\n\\n1. 리모컨이 있어서 편함 \\n\\n2. 상하, 좌우, 다...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  neighbor  likes  isAd\n",
       "0  결혼 전 신혼 살림 빠짐없이 차리면서\\n\\n이만~하면 되었다~~했고요\\n\\n그 이후...        10      5     1\n",
       "1  < 장점 >\\n\\n \\n\\n1. 리모컨이 있어서 편함 \\n\\n2. 상하, 좌우, 다...         2      6     0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"sample.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_data=np.array(df.isAd.tolist()) #종속변수 isAd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 의미없는 부분 제거\n",
    "1. 공백 (\\u200b)\n",
    "2. \\n\n",
    "3. 문장부호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 정의: 문장을 IN\n",
    "def cleaning(x):\n",
    "    x=re.sub('\\W', ' ', x) #특수문자 제거\n",
    "    x=re.sub('([ㄱ-ㅎㅏ-ㅣ]+)', '', x) #한글 자음 모음 제거\n",
    "    return x\n",
    "\n",
    "#전체 행에 전처리 적용\n",
    "df['body']=df.body.apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 형태소 분석기 이용해 토큰화\n",
    "형태소 분석기는 [Komoran](https://komorandocs.readthedocs.io/ko/latest/pykomoran/tutorial.html) 사용 <- 메소드 정리 페이지 \n",
    "\n",
    "nouns : 명사 추출  \n",
    "morphs : 형태소 추출  \n",
    "pos : 품사 부착  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 사전, 분석대상 품사 리스트 추가  \n",
    "1. userdict.txt 고유명사, 신조어 등을 새로 등록. 이들 단어에 품사 태그가 제대로 붙게 한다  \n",
    "2. pos_table.txt 분석대상 품사를 등록. 불필요한 품사를 제외한다 [komoran 품사태그](https://docs.komoran.kr/firststep/postypes.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran=Komoran(userdic='userdict.txt')\n",
    "pos=pd.read_csv('pos_table.txt', header=None, names='p')\n",
    "poslist=pos.p.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[원하는 품사만 추출](https://wikidocs.net/33799)  \n",
    "poslist에 있는 분석대상 품사만 추출한다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 행에 품사 부착 -> 각 행은 ('word', '품사') 튜플의 리스트\n",
    "df['body']=df.body.apply(komoran.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사 추출 함수 정의; 품사가 부착된 리스트를 IN\n",
    "def PosPicker(sentence):\n",
    "    clean_words=[]\n",
    "    for word in sentence:\n",
    "        if word[1] in poslist: # 품사가 분석대상 리스트에 있으면\n",
    "            clean_words.append(word[0]) # 해당 단어를 clean_words에 추가한다\n",
    "    x=' '.join(clean_words)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 행에 품사추출함수 적용\n",
    "df['body']=df.body.apply(PosPicker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 행을 다시 형태소 리스트로 변환\n",
    "df['body']=df.body.apply(komoran.morphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 불용어 제거\n",
    "불용어 리스트 stopwords.xlsx에서 관리. 2단계에서 제거되지 않은 불용어를 제거한다   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stopwords=pd.read_excel(\"stopwords.xlsx\")\n",
    "stoplist=np.array(stopwords.words.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거 함수 정의: 형태소 기준으로 나뉜 리스트를 IN \n",
    "def DelStops(sentence): \n",
    "    result=[]\n",
    "    for word in sentence:\n",
    "        if word not in stoplist:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 행에 불용어 제거 함수 적용\n",
    "df['body']=df.body.apply(DelStops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 정수 인코딩\n",
    "정수 인코딩의 원리 https://wikidocs.net/34264   \n",
    "\n",
    "**TfidVectorizer** [https://wikidocs.net/34265] 더 자세한 설명 [https://wikidocs.net/31698]  \n",
    "**가중치 부여 문서 벡터화**   \n",
    ": TF-IDF (Term Frequency - Inverse Document Frequency, 단어 빈도-역문서 빈도)\n",
    "단어 꾸러미 (BOW(Bag of Words)) 인코딩 벡터에서\n",
    "여러 문서에서 사용된 단어의 특성에 대해 문서 구별 능력이 떨어진다고 보아 낮은 가중치를 곱해 중요도를 떨어 뜨리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터화 순서는 크게 3단계\n",
    "\n",
    "count=CountVectorizer()\n",
    "tfid=TfidfVectorizer()\n",
    "\n",
    "# count.fit_transform(result)\n",
    "# tfid.fit_transform(result)\n",
    "\n",
    "# feature_matrix=count.transform(result)\n",
    "# feature_matrix2=tfid.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 리스트를 한 문장으로 합치는 함수 정의 : 단어 리스트 IN\n",
    "def wordjoin(x):\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 행에 대해 문장화 적용\n",
    "df.body=df.body.apply(wordjoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄴ지', '가능', '가전', '건조기', '결혼', '고개', '공기', '그런', '그리', '기업', '노예', '단계', '단점', '때문', '라고', '리모컨', '마케팅', '많이', '머리', '먼저', '모드', '무시', '바닥', '바람', '발맞추', '부족', '분명', '비싸', '빠짐없이', '사이', '살림', '상하', '생기', '생소', '선풍기', '세상', '소음', '숙이', '순환', '스마트', '스타일', '시대', '시원', '신혼', '애쓰', '야금', '어쩌면', '에어', '에어컨', '에어프라이어', '우리집', '유아', '이랑', '이름', '이제', '이후', '익숙', '인테리어', '자꾸', '장점', '정도', '제가', '조용', '조절', '좌우', '지금', '지나', '차리', '처음', '타이머', '터보', '포장', '필수', '필요', '해보면', '혼수', '효과']\n",
      "{'결혼': 4, '신혼': 43, '살림': 30, '빠짐없이': 28, '차리': 67, '이후': 55, '야금': 45, '부족': 25, '자꾸': 58, '때문': 13, '필요': 73, '가전': 2, '생기': 32, '기업': 9, '머리': 18, 'ㄴ지': 0, '분명': 26, '혼수': 75, '세상': 35, '많이': 17, '에어프라이어': 49, '스타일': 40, '애쓰': 44, '무시': 21, '비싸': 27, '건조기': 3, '필수': 72, '지금': 65, '그런': 7, '에어': 47, '선풍기': 34, '에어컨': 48, '시대': 41, '이제': 54, '라고': 14, '처음': 68, '이름': 53, '생소': 33, '지나': 66, '먼저': 19, '그리': 8, '사이': 29, '익숙': 56, '우리집': 50, '어쩌면': 46, '마케팅': 16, '노예': 10, '포장': 71, '해보면': 74, '발맞추': 24, '스마트': 39, '장점': 59, '리모컨': 15, '상하': 31, '좌우': 64, '공기': 6, '순환': 38, '이랑': 52, '시원': 42, '유아': 51, '모드': 20, '조용': 62, '바람': 23, '조절': 63, '가능': 1, '터보': 70, '타이머': 69, '인테리어': 57, '효과': 76, '단점': 12, '바닥': 22, '고개': 5, '숙이': 37, '단계': 11, '소음': 36, '제가': 61, '정도': 60}\n"
     ]
    }
   ],
   "source": [
    "print(tfid.get_feature_names())\n",
    "print(tfid.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클렌징이 끝난 body 열을 넣으면 여러 문서들에 나타나는 단어들에 대해서는 가중치(TF-IDF)를 낮추고, 각 문서를 구별하는 중요 단어에는 가중치를 올려 matrix로 리턴받을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x77 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 79 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 벡터화 (TFID)\n",
    "tfid.fit_transform(df.body)\n",
    "\n",
    "#bodylist=df.body.tolist()  <- 하나의 리스트로 변환하지 않아도 됨\n",
    "#tfid.fit_transform(bodylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 75)\t0.1054019430750602\n",
      "  (0, 74)\t0.1054019430750602\n",
      "  (0, 73)\t0.2108038861501204\n",
      "  (0, 72)\t0.31620582922518065\n",
      "  (0, 71)\t0.1054019430750602\n",
      "  (0, 68)\t0.1054019430750602\n",
      "  (0, 67)\t0.1054019430750602\n",
      "  (0, 66)\t0.1054019430750602\n",
      "  (0, 65)\t0.07499435060108835\n",
      "  (0, 58)\t0.1054019430750602\n",
      "  (0, 56)\t0.1054019430750602\n",
      "  (0, 55)\t0.1054019430750602\n",
      "  (0, 54)\t0.1054019430750602\n",
      "  (0, 53)\t0.2108038861501204\n",
      "  (0, 50)\t0.1054019430750602\n",
      "  (0, 49)\t0.1054019430750602\n",
      "  (0, 48)\t0.07499435060108835\n",
      "  (0, 47)\t0.2108038861501204\n",
      "  (0, 46)\t0.1054019430750602\n",
      "  (0, 45)\t0.2108038861501204\n",
      "  (0, 44)\t0.1054019430750602\n",
      "  (0, 43)\t0.1054019430750602\n",
      "  (0, 41)\t0.2108038861501204\n",
      "  (0, 40)\t0.1054019430750602\n",
      "  (0, 39)\t0.1054019430750602\n",
      "  :\t:\n",
      "  (1, 65)\t0.09592886111521996\n",
      "  (1, 64)\t0.1348246671579957\n",
      "  (1, 63)\t0.2696493343159914\n",
      "  (1, 62)\t0.1348246671579957\n",
      "  (1, 61)\t0.1348246671579957\n",
      "  (1, 60)\t0.1348246671579957\n",
      "  (1, 59)\t0.1348246671579957\n",
      "  (1, 57)\t0.1348246671579957\n",
      "  (1, 52)\t0.1348246671579957\n",
      "  (1, 51)\t0.1348246671579957\n",
      "  (1, 48)\t0.09592886111521996\n",
      "  (1, 42)\t0.1348246671579957\n",
      "  (1, 38)\t0.1348246671579957\n",
      "  (1, 37)\t0.1348246671579957\n",
      "  (1, 36)\t0.1348246671579957\n",
      "  (1, 31)\t0.1348246671579957\n",
      "  (1, 23)\t0.4044740014739871\n",
      "  (1, 22)\t0.1348246671579957\n",
      "  (1, 20)\t0.2696493343159914\n",
      "  (1, 15)\t0.1348246671579957\n",
      "  (1, 12)\t0.2696493343159914\n",
      "  (1, 11)\t0.1348246671579957\n",
      "  (1, 6)\t0.1348246671579957\n",
      "  (1, 5)\t0.1348246671579957\n",
      "  (1, 1)\t0.4044740014739871\n"
     ]
    }
   ],
   "source": [
    "# matrix로 저장 (TFID) -> 문장 수 * 단어 수 크기의 matrix가 생성된다\n",
    "feature_matrix2=tfid.transform(df.body)\n",
    "print(feature_matrix2)\n",
    "# feature_matrix3=tfid.transform(bodylist)\n",
    "# print(feature_matrix3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**matrix에 열 추가**  \n",
    "body는 2*77의 matrix로 변환되었다. 그 오른쪽에 neighbor, likes 등의 열을 추가한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix=np.zeros((feature_matrix2.shape[0], feature_matrix2.shape[1]+2))\n",
    "\n",
    "new_matrix[:,:-2]=feature_matrix2.toarray()\n",
    "new_matrix[:,-2]=df.neighbor\n",
    "new_matrix[:,-1]=df.likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10540194,  0.        ,  0.31620583,  0.10540194,  0.21080389,\n",
       "         0.        ,  0.        ,  0.10540194,  0.10540194,  0.10540194,\n",
       "         0.10540194,  0.        ,  0.        ,  0.10540194,  0.10540194,\n",
       "         0.        ,  0.10540194,  0.10540194,  0.10540194,  0.10540194,\n",
       "         0.        ,  0.10540194,  0.        ,  0.        ,  0.10540194,\n",
       "         0.10540194,  0.21080389,  0.10540194,  0.10540194,  0.10540194,\n",
       "         0.10540194,  0.        ,  0.21080389,  0.10540194,  0.10540194,\n",
       "         0.10540194,  0.        ,  0.        ,  0.        ,  0.10540194,\n",
       "         0.10540194,  0.21080389,  0.        ,  0.10540194,  0.10540194,\n",
       "         0.21080389,  0.10540194,  0.21080389,  0.07499435,  0.10540194,\n",
       "         0.10540194,  0.        ,  0.        ,  0.21080389,  0.10540194,\n",
       "         0.10540194,  0.10540194,  0.        ,  0.10540194,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.07499435,  0.10540194,  0.10540194,  0.10540194,  0.        ,\n",
       "         0.        ,  0.10540194,  0.31620583,  0.21080389,  0.10540194,\n",
       "         0.10540194,  0.        , 10.        ,  5.        ],\n",
       "       [ 0.        ,  0.404474  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.13482467,  0.13482467,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.13482467,  0.26964933,  0.        ,  0.        ,\n",
       "         0.13482467,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.26964933,  0.        ,  0.13482467,  0.404474  ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.13482467,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.13482467,  0.13482467,  0.13482467,  0.        ,\n",
       "         0.        ,  0.        ,  0.13482467,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.09592886,  0.        ,\n",
       "         0.        ,  0.13482467,  0.13482467,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.13482467,  0.        ,  0.13482467,\n",
       "         0.13482467,  0.13482467,  0.13482467,  0.26964933,  0.13482467,\n",
       "         0.09592886,  0.        ,  0.        ,  0.        ,  0.13482467,\n",
       "         0.26964933,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.13482467,  2.        ,  6.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델링\n",
    "(나이브 베이즈 모델)[https://wikidocs.net/35435]  \n",
    "(랜덤포레스트)  \n",
    "(딥러닝)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 종속변수와 독립변수로 나누기 \n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data=df.drop(['isAd'],axis=1)\n",
    "# target_data=df.isAd\n",
    "\n",
    "# ## 2) 각각을 8:2로 나누기 (train과 test 셋)\n",
    "# x_train,x_test,y_train,y_test=train_test_split(train_data, target_data, test_size=0.2)\n",
    "\n",
    "# ## 3) train을 다시 8:2로 나누기 (train과 valid)\n",
    "# x_train,x_valid,y_train,y_valid=train_test_split(x_train,y_train, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training set :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest= RandomForestClassifier(n_estimators=10) \n",
    "forest.fit(new_matrix, target_data)\n",
    "\n",
    "print(\" training set : \", forest.score(new_matrix, target_data))\n",
    "# print(\" validation set : \", forest.score(feature_matrix2, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류에 중요한 특성은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 max_depth, n_estimators 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 모델\n",
    "https://wikidocs.net/34389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.externals import joblib\n",
    "#pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(tfid, 'model/test_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=BernoulliNB(alpha=1.0)\n",
    "model.fit(new_matrix, target_data) #정수화한 matrix를 넣어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(model.score(new_matrix, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 모델 예측\n",
    "학습에 사용하지 않은 값 넣어 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빈도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 한국어 설정\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "plt.rcParams[\"font.family\"]=\"Malgun Gothic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolaw=Text(komoran.nouns(temp))\n",
    "kolaw.plot(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
